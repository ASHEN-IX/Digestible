version: '3.8'


  # 1. The API Gateway Service
services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    volumes:
      - .:/app  # This is the MAGIC line: it syncs your computer with the container
    environment:
      - DATABASE_URL=postgresql+asyncpg://user:password@db:5432/digestible_db
      - PYTHONPATH=/app
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis

  # 2. The Task Worker Service
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    # Add this environment variable:
    environment:
      - PYTHONPATH=/app
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - REDIS_URL=redis://redis:6379/0
      - DB_HOST=db  # Hostname for the local Postgres container
      - DB_NAME=digestible_db
      - DB_USER=user
      - DB_PASSWORD=password
      # Add environment for external APIs (e.g., OpenAI, S3)
      - OPENAI_API_KEY=your_openai_key
      - AWS_S3_BUCKET=your-bucket-name
    # Ensure the command points to the package:
    command: celery -A tasks worker --loglevel=info
    depends_on:
      - redis
      - db

  # 3. The Redis Message Broker
  redis:
    image: "redis:latest"
    expose:
      - 6379
    # Volumes are optional for Redis locally but good practice
    # volumes:
    #   - redis_data:/data 

  # 4. The Local PostgreSQL Persistence Layer (for Dev)
  db:
    image: "postgres:14-alpine"
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=digestible_db
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    expose:
      - 5432

volumes:
  postgres_data:
  # redis_data: # Uncomment if you decide to add Redis persistence